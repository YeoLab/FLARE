from glob import glob
import json
import pandas as pd
import sys
from collections import defaultdict
import numpy as np
import os

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Regions for which edit fractions should be calculated should be in the following format, 
# with headings, and end with a consistent underscored suffix, i.e. _0 _1, _2, _3... _n.
#
# Region IDs must be listed in a gene:subregion:start-end format.
#
# Example rows:
#
# region_id    chrom   start   end     strand  subregion       region  gene
# DDX11L1:exon_0:11869-11899      chr1    11869   11899   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11884-11914      chr1    11884   11914   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11899-11929      chr1    11899   11929   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11914-11944      chr1    11914   11944   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11929-11959      chr1    11929   11959   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11944-11974      chr1    11944   11974   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11959-11989      chr1    11959   11989   +       exon_0  exon    DDX11L1
# DDX11L1:exon_0:11974-12004      chr1    11974   12004   +       exon_0  exon    DDX11L1
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


regions = config["regions"]
region_files = glob('{}/*'.format(regions))
region_suffixes = [r.split('_')[-1] for r in region_files if '.sh' not in r]

# Fish out the absolute path to the json config file so we can use it later on in certain rules
args = sys.argv
print('args are ', args)

def get_val_from_args(val_names, absolute=False):
    val_tags = ['--{}'.format(v) for v in val_names] + ['-{}'.format(v) for v in val_names]
    print(val_tags)
    
    val_present = None
    for val_tag in val_tags:
        for arg in args:
            if val_tag == arg:
                val_present = val_tag
                print('Found {}'.format(val_tag))
                break
    if not val_present:
        print("Could not find {} in args".format(val_names))
        return None
    
    val = args[args.index(val_present) + 1]
    print('{} is {}'.format(val_present, val))
    
    if absolute:
        return val
    else:
        snakemake_directory = '/'.join(val.rstrip('/').split('/')[:-2])
        print('STAMP directory is {}'.format(snakemake_directory))

        return snakemake_directory



snakemake_directory = get_val_from_args(['snakefile', 's', 'profile'])
scripts_directory='{}/workflow_FLARE/scripts/'.format(snakemake_directory)
print("Scripts directory is {}".format(scripts_directory))

config_path = get_val_from_args(["configfile", "configfiles"], absolute=True)
    
print("Config path is {}".format(config_path))

if 'max_merge_dist' not in config:
    config['max_merge_dist'] = 15

if 'fdr_threshold' not in config:
    config['fdr_threshold'] = 0.1
    
    
print("Max merge distance: {}".format(config['max_merge_dist']))
print("FDR filtering threshold: {}".format(config['fdr_threshold']))

rule all:
    input:
        bedgraph=os.path.join(config["output_folder"], "bedgraphs", config["label"] + "_editc.bedgraph"),
        merged_filtered_region_outputs=os.path.join(config["output_folder"], "editc_outputs", config["label"] + "_filtered_regions.tsv"),
        scored_peaks=os.path.join(config["output_folder"], "FLARE", config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".scored.tsv")

        
rule make_editc_array_jobs_script:
    input:
        fasta=config["fasta"],
        forward_bw=config["forward_bw"],
        reverse_bw=config["reverse_bw"],
        stamp_sites_file=config["stamp_sites_file"]
    params:
        threads=1,
        run_time="00:05:00",
        label=config["label"],
        directory=config["output_folder"],
        regions=config["regions"],
    output:
        editc_array_jobs_scripts=expand(os.path.join(config["output_folder"], "bash_scripts", config["label"], config["label"] + "_bash_job_edit_c_{part}.sh"), part=region_suffixes)
    threads: 1
    shell:
        """
        regions_directory={params.regions}
        directory={params.directory}
        label={params.label}
        
        mkdir -p $directory/editc_outputs/$label;

        python {scripts_directory}/make_array_jobs_for_editc.py \
            --sample_id $label \
            --input_json {config_path} \
            --main_directory {params.directory} \
            --scripts_directory {scripts_directory} \
            --regions_directory $regions_directory
        """
        
rule run_editc_array_job:
    input:
        editc_array_jobs_scripts=expand(os.path.join(config["output_folder"], "bash_scripts", config["label"], config["label"] + "_bash_job_edit_c_{part}.sh"), part=region_suffixes)
    output:
        editc_outputs=os.path.join(config["output_folder"], "editc_outputs", config["label"], config["label"] + "_edit_c_for_all_regions_{part}_all_info.tsv"),
        filtered_region_outputs=os.path.join(config["output_folder"], "editc_outputs", config["label"], config["label"] + "_edit_c_for_all_regions_{part}_all_info.filtered_regions.tsv")
    params:
        threads=8,
        directory=config["output_folder"],
        sample_name=config["label"],
        run_time="04:00:00"
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """
        bash {params.directory}/bash_scripts/{params.sample_name}/{params.sample_name}_bash_job_edit_c_{wildcards.part}.sh
        """
        
rule make_merged_filtered_regions:
    input:
        filtered_region_outputs=expand(os.path.join(config["output_folder"], "editc_outputs", config["label"], config["label"] + "_edit_c_for_all_regions_{i}_all_info.filtered_regions.tsv"),
        i=region_suffixes)
    output:
        merged_filtered_region_outputs=os.path.join(config["output_folder"], "editc_outputs", config["label"] + "_filtered_regions.tsv")
    params:
        threads=1,
        run_time="00:30:00",
        label=config["label"],
        directory=config["output_folder"]
    shell:
        """        
        echo 'region_id\tchrom\tstart\tend\tstrand\tsubregion\tregion\tgene' > {params.directory}/editc_outputs/{params.label}_filtered_regions.tsv
        cat {params.directory}/editc_outputs/{params.label}/*filtered_regions.tsv >> {params.directory}/editc_outputs/{params.label}_filtered_regions.tsv
        """
        

rule make_merged_editc_bedgraph:
    input:
        editc_outputs=expand(os.path.join(config["output_folder"], "editc_outputs", config["label"], config["label"] + "_edit_c_for_all_regions_{i}_all_info.tsv"), 
        i=region_suffixes)
    output:
        merged_editc=os.path.join(config["output_folder"], "editc_outputs", config["label"] + "_edit_c_for_all_regions.tsv"),
        bedgraph=os.path.join(config["output_folder"], "bedgraphs", config["label"] + "_editc.bedgraph")
    params:
        threads=1,
        run_time="00:30:00",
        label=config["label"],
        directory=config["output_folder"]
    shell:
        """      
        echo "region_id\tchrom\tstart\tend\tedit_fraction\tstrand\ttarget_bases\tedited_bases\tnum_edited_reads\ttotal_reads_in_region\tfraction_reads_edited\tmean_depth\tnum_substrate_bases\tsubregion_coverage\tsubregion_conversions\tregion_coverage\tregion_conversions\tgene_coverage\tgene_conversions"  > {params.directory}/editc_outputs/{params.label}_edit_c_for_all_regions.tsv
        cat {params.directory}/editc_outputs/{params.label}/*all_info.tsv | grep -v chrom >> {params.directory}/editc_outputs/{params.label}_edit_c_for_all_regions.tsv
        sed -i 's/inf/0.0/g' {params.directory}/editc_outputs/{params.label}_edit_c_for_all_regions.tsv
        
        # Make bedgraph from the appropriate columns in the edit c output file
        echo "making {params.directory}/bedgraphs if it doesn't exist yet..."
        mkdir -p {params.directory}/bedgraphs;

        # The awk 4 is to only keep rows that don't have a 0.0 value in the 4th column (i.e. de-sparsify) to reduce file size
        cat {params.directory}/editc_outputs/{params.label}_edit_c_for_all_regions.tsv | cut -f2,3,4,5 | tail -n +2 | awk '$4' > {params.directory}/bedgraphs/{params.label}_editc.bedgraph;
        """

        
rule poisson_scoring:
    input:
        merged_editc=os.path.join(config["output_folder"], "editc_outputs", config["label"] + "_edit_c_for_all_regions.tsv"),
        merged_filtered_region_outputs=os.path.join(config["output_folder"], "editc_outputs", config["label"] + "_filtered_regions.tsv")
    output:
        regions_with_fdr=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_all_regions_with_fdr.tsv")
    params:
        threads=1,
        run_time="00:30:00",
        label=config["label"],
        directory=config["output_folder"]
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """
        echo "making {params.directory}/FLARE/{params.label} if it doesn't exist yet..."
        mkdir -p {params.directory}/FLARE/{params.label};

        # Poisson score the peaks
        echo "Running: python {scripts_directory}/multipoisson_peak_calling.py {config_path} --edit_c_regions {input.merged_editc} --file_prefix {params.label};"
        python {scripts_directory}/multipoisson_peak_calling.py {config_path} --edit_c_regions {input.merged_editc};
        """
      
        
rule filter_by_fdr:
    input: 
        regions_with_fdr=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_all_regions_with_fdr.tsv")
    output:
        regions_with_fdr_filtered=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + ".fdr_" + str(config["fdr_threshold"]) + ".bed")
    params:
        threads=1,
        run_time="00:10:00",
        label=config["label"],
        fdr_threshold=config["fdr_threshold"],
        directory=config["output_folder"]
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """
        python {scripts_directory}/filter_by_fdr.py {input.regions_with_fdr} {params.fdr_threshold} {output.regions_with_fdr_filtered}
        """
        
        
rule merge_peaks:
    input:
        regions_with_fdr_filtered=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + ".fdr_" + str(config["fdr_threshold"]) + ".bed")
    output:
        merged_peaks=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".merged.bed")
    params:
        threads=1,
        run_time="00:10:00",
        label=config["label"],
        fdr_threshold=config["fdr_threshold"],
        directory=config["output_folder"],
        max_merge_dist=config["max_merge_dist"]
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """
        # Bedtools merge peaks
        echo "sorting and then merging {input.regions_with_fdr_filtered}" 
        
        bedtools sort -i {input.regions_with_fdr_filtered} | bedtools merge -s -d {params.max_merge_dist} -c 4,5,6,7 -o mean,distinct,distinct,distinct > {output.merged_peaks}
        """
        
rule reindex_merged_peaks:
    input:
        merged_peaks=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".merged.bed")
    output:
        combined_peaks_indexed=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".regions")
    params:
        threads=1,
        run_time="00:20:00",
        directory=config["output_folder"]
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """        
        python {scripts_directory}/reindex_merged_peaks.py {input.merged_peaks} {output.combined_peaks_indexed}
        """
 
 
rule peak_edit_fraction:
    input:
        combined_peaks_indexed=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".regions")
    output:
        combined_peaks_indexed_with_edit_fraction=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".edit_fraction.tsv")
    params:
        threads=8,
        directory=config["output_folder"],
        sample_name=config["label"],
        run_time="6:00:00"
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """
        python {scripts_directory}/calculate_edit_c_for_regions.py {config_path} --regions_override {input.combined_peaks_indexed} --outfile_override {output.combined_peaks_indexed_with_edit_fraction} --final_peaks True
        """
        

rule score_peaks:
    input:
        regions_with_fdr=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_all_regions_with_fdr.tsv"),
        combined_peaks_indexed_with_edit_fraction=os.path.join(config["output_folder"], "FLARE", config["label"], config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".edit_fraction.tsv")
    output:
        scored_peaks=os.path.join(config["output_folder"], "FLARE", config["label"] + "_merged_sorted_peaks.fdr_" + str(config["fdr_threshold"]) + ".d_" + str(config["max_merge_dist"]) + ".scored.tsv")
    params:
        sample_name=config["label"],
        run_time="1:00:00",
        threads=1
    singularity:
        "docker://ekofman/editc:v2"
    shell:
        """        
        python {scripts_directory}/score_peaks.py {input.combined_peaks_indexed_with_edit_fraction} {output.scored_peaks} {input.regions_with_fdr}
        """
